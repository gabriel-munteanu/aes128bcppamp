TODO:

1. [Done] Implement encryption and decryption on GPU 
2. [Done] Study about and implement key generation from a simple password
	Solution: just copy the password and fill the rest of the key with NULL. If key >16 chars only the first 16 chars are used
3. [Done] Check for memory limits
	Conclusion: I, as programmer, must take care of the maximum memory allocated on the device
4. [Done] Use classes for implementation for a more modular code
5. [Done] Write a parallel implementation on CPU
6. Study about TDR: Time out Detection & Recovery. What can be done to avoid it?
7. Implement performance tests from which will result a ranking and memory limits
	- write performance test specific for C++ AMP(memory copy time, kernel execution time)
8. Memory management module( CPU & GPU ) 
	- if we have a 8GB file but only 1GB of RAM memory free?
	- if our GPU(s) has only 512MB? 


98. Use all available resources for one computation (heterogeneous computing)
99. Compare against real implementation(libCrypto?) http://en.wikipedia.org/wiki/Crypto%2B%2B


Optimizations?
	- use staging arrays instead of simple arrays http://blogs.msdn.com/b/nativeconcurrency/archive/2011/11/10/staging-arrays-in-c-amp.aspx


Ideas:
	- run test with chunks of data size of 2^n bytes
	- for data <= 2mb it's not worth to run on GPU but maybe on CPU with AMP?
	- for some scenarios we can use some hardcoded decisions even if the hardware is different(ideea above)

Class:
	- there will be a base class
	- one implementation can have 'multiple computation ways'. AMP implementation will have computations ways as 
many accelerators are found on the system. CPU implementations will have only one way
	- there must be a function that return an array with function. Each function is a 'computation way'
	- the base class will contain the performance test? or there will be another class?


To think of:
	- if there is no 'not emulated' accelerator it's worth trying all the tests? 

Memory Management Module will take care of this:
- load data in RAM as much as it can
- if we process data on a GPU then it will give to the PU no more data than it can load in memory